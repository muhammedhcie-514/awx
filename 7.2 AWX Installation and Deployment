7.2.1 Preparing the Ceph Resource Pool
Step 1 Create a resource pool.
The AWX database stores the file system CephFS provided by Ceph, and the capacity is
not less than 8 GB. Therefore, before installing and deploying AWX, create the required
CephFS resource pool.
[ceph: root@ceph01 /]# ceph osd pool create metadata_for_awx
[ceph: root@ceph01 /]# ceph osd pool create data_for_awx
[ceph: root@ceph01 /]# ceph fs new pool_for_awx metadata_for_awx data_for_awx


Step 2 Create a user.
After the resource pool is created, create a user for AWX. The user should have the read
and write permissions on the resource pool created in the preceding step.
[ceph: root@ceph01 /]# ceph fs authorize pool_for_awx client.awx / rwps -o ceph.client.awx.keyring



7.2.2 Configuring Ceph-csi Resources
Step 1 Compile and deploy YAML files of related components.
Compile the config-map file based on the preceding sections. The content of the csiconfig-map.yaml file is as follows:
#
# /!\ DO NOT MODIFY THIS FILE
#
# This file has been automatically generated by Ceph-CSI yamlgen.
# The source for the contents can be found in the api/deploy directory, make
# your modifications there.
#
---
apiVersion: v1
kind: ConfigMap
metadata:
 name: "ceph-csi-config"
data:
 config.json: |-
 [
 {
 "clusterID": "d5faf9ba-56c0-11ee-9ffe-fa163edb3348",
 "monitors": [
 "192.168.0.21:6789",
 "192.168.0.22:6789",
 "192.168.0.23:6789"
 ]
 }
 ]
The content of ceph-conf-map.yaml is as follows:
---
apiVersion: v1
kind: ConfigMap
data:
 config.json: |-
 {}
metadata:
 name: ceph-csi-encryption-kms-config
---
apiVersion: v1
kind: ConfigMap
data:
 ceph.conf: |
 [global]
 auth_cluster_required = cephx
 auth_service_required = cephx
 auth_client_required = cephx
 # keyring is a required key and its value should be empty
 keyring: |
metadata:
 name: ceph-config




Change the 56th and 88th lines in the csi-cephfsplugin-provisioner.yaml file to --extracreate-metadata=false.

After the modification, run the following command to deploy all ConfigMaps:
kubectl apply -f ceph-conf-map.yaml -f csi-config-map.yaml -f csi-nodeplugin-rbac.yaml -f csiprovisioner-rbac.yaml

Run the following command to deploy the pod required by ceph-csi:
kubectl apply -f csi-cephfsplugin-provisioner.yaml -f csi-cephfsplugin.yaml -f csidriver.yaml --
validate=false


Step 2 Compile the secret and sc configuration files.
Copy the secret.yaml file from the example directory and add the user information
created in step 2 in section 5.2.1 to the file.
---
apiVersion: v1
kind: Secret
metadata:
 name: csi-cephfs-secret
 namespace: awx
stringData:
 # Required for statically provisioned volumes
 userID: awx
 userKey: AQAHjkllPax2CBAACfRE0qQUqmZzjQtOxzQHIg==
 # Required for dynamically provisioned volumes
 adminID: admin
 adminKey: AQA9UgllOALJIRAAvKYqPlEX8zZcLWgaY6F1OA==
 # Encryption passphrase
 encryptionPassphrase: test_passphrase
The value of namespace in the file must be the same as the namespace used by AWX
Operator. Run the following command on the Ceph management node to query the user
information:
[ceph: root@ceph01 /]# ceph auth get client.awx


Use the same method to find the values of adminID and adminKey.
After the modification, secret is not deployed because the namespace awx has not been
created.
Copy the storageclass.yaml file from the example directory and add the resource pool
information created in step 1 in section 7.2.1 to the file.
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
 name: csi-cephfs-sc
provisioner: cephfs.csi.ceph.com
parameters:
 clusterID: d5faf9ba-56c0-11ee-9ffe-fa163edb3348
 fsName: pool_for_awx
 pool: data_for_awx
 csi.storage.k8s.io/provisioner-secret-name: csi-cephfs-secret
 csi.storage.k8s.io/provisioner-secret-namespace: awx
 csi.storage.k8s.io/controller-expand-secret-name: csi-cephfs-secret
 csi.storage.k8s.io/controller-expand-secret-namespace: awx
 csi.storage.k8s.io/node-stage-secret-name: csi-cephfs-secret
 csi.storage.k8s.io/node-stage-secret-namespace: awx
 mounter: kernel
reclaimPolicy: Delete
allowVolumeExpansion: true
Run the ceph mon dump command on the Ceph controller node to query the cluster ID.
ceph mon dump
fsName and pool correspond to name and data pool in the output of the ceph fs ls
command on the Ceph controller node, respectively.
ceph fs ls


7.2.3 AWX Installation and Deployment
Step 1 Compile and deploy a kustomization file.
Create a kustomization.yaml file as follows:
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
 # Find the latest tag here: https://github.com/ansible/awx-operator/releases
 - https://gitee.com/yftyxa/awx-operator/config/default?ref=2.7.1
# et the image tags to match the git version from above
images:
 - name: swr.cn-east-3.myhuaweicloud.com/hcie_openeuler/awx-operator
 newTag: latest
# Specify a custom namespace in which to install AWX
namespace: awx
The namespace specified in the file must be the same as that in secret and storageClass
in section 7.2.2. After the file is compiled, run the following command in the directory
where the file is located:
[root@k8smaster1 awx1.0]# kubectl apply -k .

Run the following command to check the deployment result:
[root@k8smaster1 awx1.0]# kubectl get pods -n awx


After the awx-operator-controller-manager status becomes normal, go to the next
step.


Step 2 Deploy other components.
Run the following command to deploy the secret and storageClass configured in section
7.2.2:
[root@k8smaster1 kubernetes]# kubectl apply -f secret.yaml -f storageclass.yaml
After the deployment is complete, check their status.
kubectl get secret -n awx

Compile the YAML file corresponding to the AWX server in the directory where the
kustomization.yaml file is located and name the file awx-demo.yaml. The content is as
follows:
---
apiVersion: awx.ansible.com/v1beta1
kind: AWX
metadata:
 name: awx-openeuler
spec:
 service_type: nodeport
 # nodeport_port: 30080
After the compilation is complete, add it to the kustomization resource.
resources: 
  -https://qitee.com/yftyxa/awx-operator/config - awx-demo.yaml


Wait for about two minutes until a PVC is created, which is in the Pending state. Edit the
PVC and set its storageClass to csi-cephfs-sc created in section 7.2.2.
[root@k8smaster1 awx1.0]# kubectl get pvc -n awx



[root@k8smaster1 awx1.0]# kubectl get pvc postgres-13-awx-openeuler-postgres-13-0 -n awx -
o=yaml > pvc.yml
Specify the sc name in the pvc.yml file as follows:
[root@k8smaster1 awx1.0]# cat pvc.yml
……
spec:
 accessModes:
 - ReadWriteOnce
 resources:
 requests:
 storage: 8Gi
 volumeMode: Filesystem
 storageClassName: csi-cephfs-sc
…….
Delete the original PVC and use pvc.yml to deploy a PVC again.
[root@k8smaster1 awx1.0]# kubectl delete pvc postgres-13-awx-openeuler-postgres-13-0 --force -n
awx
warning: Immediate deletion does not wait for confirmation that the running resource has been
terminated. The resource may continue to run on the cluster indefinitely.
persistentvolumeclaim "postgres-13-awx-openeuler-postgres-13-0" force deleted
[root@k8smaster1 awx1.0]# kubectl apply -f pvc.yml
persistentvolumeclaim/postgres-13-awx-openeuler-postgres-13-0 created


Wait until the PVC status changes to Bound
kubectl get pvc -n awx

Run the kubectl get pods -n awx command to check whether the pod status is normal.
If it is normal, the information similar to the following figure is displayed.

kubectl get pods -n awx

Log in to the pod and check whether the AWX service is normal.
[root@k8smaster1 awx1.0]# kubectl exec -it awx-openeuler-task-65d7d9d984-m9bq7 -c awxopeneuler-task -n awx -- /bin/bash
bash-5.1$ awx-manage version
If the returned information is correct, go to the next step.

Step 3 (Optional) Deploy Ingress.
If Ingress has been deployed, skip this step.
Copy the content from https://github.com/kubernetes/ingress-nginx/blob/controllerv1.6.4/deploy/static/provider/baremetal/deploy.yaml to the ingress.yaml file.
Replace the involved image with swr.cn-east3.myhuaweicloud.com/hcie_openeuler/controller:v1.6.4 and swr.cn-east3.myhuaweicloud.com/hcie_openeuler/kube-webhook-certgen:v20220916-
gd32f8c343.
Run the kubectl apply -f ingress.yaml command and wait until the deployment is
complete.

kubectl get pod -n ingress-nginx

The content of the Ingress configuration file required for compiling AWX is as follows:

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
 name: awx
 namespace: awx
 annotations:
kubernetes.io/ingress.class: "nginx"
nginx.ingress.kubernetes.io/rewrite-target: /$2
nginx.ingress.kubernetes.io/use-regex: "true"
spec:
rules:
 - host: www.openeuler-hcie.com
 http:
 paths:
 - backend:
 service:
 name: awx-openeuler-service
 port:
 number: 80
 path: /awx(/|$)(.*)
 pathType: Prefix


Query the service name and number in the file.
kubectl get svc -n awx



After the configuration is complete, check the svc corresponding to ingress-controller.
kubectl get svc -n ingress-nginx

View details about the created Ingress.

kubectl describe ingress awx -n awx


Manually bind the domain name www.openeuler-hcie.com to 10.0.0.12 or the
corresponding EIP. Then, you can access AWX through www.openeulerhcie.com:32453/awx/#/login on the client.


After the installation is complete, view the default password of the admin user.
[root@k8smaster1 ~]# kubectl get secret awx-openeuler-admin-password -n awx -o
jsonpath="{.data.password}" | base64 --decode
7yv37sFLaj3EPQ00LgwuT3sOoVQLkCgg
Use the password to log in to the system.

